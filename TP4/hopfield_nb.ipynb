{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TP4 Hopfield"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from asciiHandler import asciiStringToLettersMatrix\n",
    "from hopfield import propagatePattern,calculateWeights,sgn,addNoise,printLetter,printLetterBipolar,printLetterBipolarMatrix,plotLetterMap,plotEnergy,isPattern,plotSpuriousStatesCountPerNoiseProbability\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import random\n",
    "from string import ascii_lowercase\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#PROPIEDADES DE CONFIGURACION\n",
    "hopfieldProperties = {\n",
    "    'seed': 10,\n",
    "    'noiseProbability':0,\n",
    "    'lettersCombo': ['o','g','c','d'],\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#SETEO DEL RANDOM SEED\n",
    "np.random.seed(hopfieldProperties.get('seed'))\n",
    "random.seed(hopfieldProperties.get('seed'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alphabet=\"\"\"\n",
    " ###  ####   ###  ####  ##### #####  ###  #   # ##### ##### #   # #     #   #\n",
    "#   # #   # #   # #   # #     #     #     #   #   #     #   #  #  #     ## ##\n",
    "##### ####  #     #   # ####  ####  #  ## #####   #     #   ###   #     # # #\n",
    "#   # #   # #   # #   # #     #     #   # #   #   #   # #   #  #  #     #   #\n",
    "#   # ####   ###  ####  ##### #      ###  #   # ##### ###   #   # ##### #   #\n",
    "\n",
    "#   #  ###  ####   ###  ####   ###  ##### #   # #   # #   # #   # #   # #####\n",
    "##  # #   # #   # #   # #   # #       #   #   # #   # #   #  # #   # #     # \n",
    "# # # #   # ####  #   # ####   ###    #   #   #  # #  # # #   #     #     #  \n",
    "#  ## #   # #     #  #  #   #     #   #   #   #  # #  ## ##  # #    #    #   \n",
    "#   #  ###  #      ## # #   #  ###    #    ###    #   #   # #   #   #   #####\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#MOVE EACH ASCII TO A LETTER MATRIX\n",
    "(alphabetASCII,alphabetASCIIBipolar)=asciiStringToLettersMatrix()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#BUSCAR LETRAS MAS ORTOGONALES\n",
    "ortogonality=np.zeros((len(alphabetASCIIBipolar),len(alphabetASCIIBipolar)))\n",
    "alphabet = [c for c in ascii_lowercase]\n",
    "print(np.dot(alphabetASCIIBipolar[1],alphabetASCIIBipolar[0]))\n",
    "for i in range(0,len(alphabetASCIIBipolar)):\n",
    "    for j in range(0,len(alphabetASCIIBipolar)):\n",
    "        ortogonality[i][j]=np.dot(alphabetASCIIBipolar[i],alphabetASCIIBipolar[j])\n",
    "df_cm = pd.DataFrame(ortogonality, index = [i for i in ascii_lowercase],\n",
    "                  columns = [i for i in ascii_lowercase])\n",
    "plt.figure(figsize = (15,9))\n",
    "sns.heatmap(data=df_cm,cmap=sns.color_palette(\"vlag\", as_cmap=True),annot=True)\n",
    "\n",
    "#sns.heatmap(data=df_cm,cmap=sns.diverging_palette(250, 30, l=65, center=\"dark\", as_cmap=True))\n",
    "plt.title(\"Producto interno entre Letras\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CALCULAR 4 LETRAS MAS ORTOGONALES yMENOS ORTOGONALES\n",
    "min_ortogonality_letters=[]\n",
    "min_ortogonality=[25**6]\n",
    "for i in range(0,len(alphabet)):\n",
    "    for j in range(0,len(alphabet)):\n",
    "        for k in range(0,len(alphabet)):\n",
    "            for r in range(0,len(alphabet)):\n",
    "                tot_ortogonality=ortogonality[i][j]*ortogonality[i][k]*ortogonality[i][r]*ortogonality[j][k]*ortogonality[j][r]*ortogonality[r][k]\n",
    "                if(np.abs(tot_ortogonality)<=min_ortogonality[0] and i!=j and i!=k and i!=r and j!=k and j!=r and k!=r):\n",
    "                    min_ortogonality_letters.insert(0,f\"{ascii_lowercase[i]}{ascii_lowercase[j]}{ascii_lowercase[k]}{ascii_lowercase[r]}\")\n",
    "                    min_ortogonality.insert(0,np.abs(tot_ortogonality))\n",
    "print(min_ortogonality_letters)\n",
    "print(min_ortogonality)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CALCULAR 4 LETRAS MENOS ORTOGONALES\n",
    "max_ortogonality_letters=[]\n",
    "max_ortogonality=[0]\n",
    "for i in range(0,len(alphabet)):\n",
    "    for j in range(0,len(alphabet)):\n",
    "        for k in range(0,len(alphabet)):\n",
    "            for r in range(0,len(alphabet)):\n",
    "                tot_ortogonality=ortogonality[i][j]*ortogonality[i][k]*ortogonality[i][r]*ortogonality[j][k]*ortogonality[j][r]*ortogonality[r][k]\n",
    "                if(np.abs(tot_ortogonality)>=max_ortogonality[0] and i!=j and i!=k and i!=r and j!=k and j!=r and k!=r):\n",
    "                    max_ortogonality_letters.insert(0,f\"{ascii_lowercase[i]}{ascii_lowercase[j]}{ascii_lowercase[k]}{ascii_lowercase[r]}\")\n",
    "                    max_ortogonality.insert(0,np.abs(tot_ortogonality))\n",
    "print(max_ortogonality_letters)\n",
    "print(max_ortogonality)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# AGARRAR 4 LETRAS\n",
    "patterns_letters=hopfieldProperties['lettersCombo']\n",
    "patterns=[]\n",
    "for i in range(0,len(patterns_letters)):\n",
    "    patterns.append(alphabetASCIIBipolar[ascii_lowercase.index(patterns_letters[i])])\n",
    "# CALCULAR LOS PESOS DE LA RED\n",
    "W=calculateWeights(patterns)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#VERIFICAR PATRONES\n",
    "results=[]\n",
    "energies=[]\n",
    "iterations=[]\n",
    "noise_probability=hopfieldProperties['noiseProbability']\n",
    "patternsWNoise=[]\n",
    "# Add Noise\n",
    "for i in range(0,len(patterns)):\n",
    "    patternsWNoise.append(addNoise(noise_probability,patterns[i]))\n",
    "# Propagate patterns with noise\n",
    "for p in range(0,len(patterns_letters)):\n",
    "    results.append([])\n",
    "    energies.append([])\n",
    "    results[p]= propagatePattern(W,patternsWNoise[p])[0]\n",
    "    energies[p]= propagatePattern(W,patternsWNoise[p])[1]\n",
    "    iterations.append(len(results[p])-1)\n",
    "\n",
    "# Plot Results (1st Row => Original pattern\n",
    "#               2nd Row => Pattern with noise\n",
    "#               3rd+ Row => Propagation     )    \n",
    "figure, axes = plt.subplots(max(iterations)+2, 4, sharex=True, figsize=(19,7))\n",
    "\n",
    "for i in range(0,len(patterns)):\n",
    "    plotLetterMap(patterns[i],axes=axes[0, i])\n",
    "    plotLetterMap(patternsWNoise[i],axes=axes[1, i])\n",
    "    for j in range(0,len(results[i])-1):\n",
    "        plotLetterMap(results[i][j],axes=axes[j+2, i])\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#GRAFICAR LA ENERGIA EN FUNCION DE LAS ITERACIONES PARA LOS PATRONES CON RUIDO\n",
    "plotEnergy(energies,patterns_letters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#GRAFICAR CANTIDAD DE ESTADOS ESPUREOS EN FUNCION DE LA PROBABILIDAD DE RUIDO UTILIZADA\n",
    "\n",
    "#Crear patrones de letras\n",
    "patterns_length=4\n",
    "patterns_letters=[['k','n','s','v'],['a','u','k','j'],['s','p','a','q'],['a','b','c','d'],['v','t','r','q'],['o','g','c','d']]\n",
    "patterns=[]\n",
    "for i in range(0,len(patterns_letters)):\n",
    "    patterns.append([])\n",
    "    for j in range(0,len(patterns_letters[i])):\n",
    "        patterns[i].append(alphabetASCIIBipolar[ascii_lowercase.index(patterns_letters[i][j])])\n",
    "\n",
    "#Creamos una lista con las probabilidades de ruido a evaluar, y otra para ir guardando por cada una la cant de estados espureos\n",
    "noiseProbabilities = [0,0.05,0.1,0.2,0.3,0.4,0.5,0.6,0.7,0.8]\n",
    "spuriousStatesCount=[]\n",
    "\n",
    "#Por cada una, ejecutamos Hopfield y vemos cuantos estados espureos se obtienen\n",
    "for p in range(0,len(patterns)):\n",
    "    spuriousStatesCount.append([])\n",
    "    for i in range(0,len(noiseProbabilities)):\n",
    "        results=[]\n",
    "        patternsWNoise=[]\n",
    "        # Add Noise\n",
    "        for j in range(0,100*patterns_length):\n",
    "            patternsWNoise.append(addNoise(noiseProbabilities[i],patterns[p][j%patterns_length]))\n",
    "        # Propagate patterns with noise\n",
    "        spuriousStatesCountPerNoiseProbability = 0\n",
    "        for k in range(0,len(patternsWNoise)):\n",
    "            results.append([])\n",
    "            W=calculateWeights(patterns[p])\n",
    "            results[k]= propagatePattern(W,patternsWNoise[k])[0]\n",
    "            if(not isPattern(results[k][-1],patterns[p])):\n",
    "                spuriousStatesCountPerNoiseProbability+=1\n",
    "        spuriousStatesCount[p].append(spuriousStatesCountPerNoiseProbability/400)\n",
    "print(spuriousStatesCount)\n",
    "#Finalmente, realizamos el grafico\n",
    "plotSpuriousStatesCountPerNoiseProbability(patterns_letters,noiseProbabilities,spuriousStatesCount)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "0bc0a0dd210023b70c8f69fe0bf4ea2234dd88804395be62034c373d5e797fc5"
  },
  "kernelspec": {
   "display_name": "Python 3.10.2 ('venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
