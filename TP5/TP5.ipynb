{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#IMPORTS INICIALES\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from autoencoderManager import AutoencoderManager\n",
    "from fonts import getCharacterMatrix,getCharacterMap,getFormattedFont\n",
    "from helpers.configHelper import ConfigHelper\n",
    "from graph import plotErrorAgainstSteps\n",
    "from noise import addNoise\n",
    "import pickle\n",
    "from os.path import exists\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TP5 - Deep Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#LEEMOS LOS PARAMETROS DEL CONFIG HELPER\n",
    "\n",
    "configPath=\"./config/config.json\"\n",
    "configHelper = ConfigHelper(configPath)\n",
    "(architecture,encoderActivationFunction,latentSpaceActivationFunction,decoderActivationFunction,encoderBeta,latentSpaceBeta,decoderBeta,learningRate,maxEpochs,maxToleranceExponent,randomSeed,font,noiseProbability) = configHelper.getProperties()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ejercicio 1\n",
    "### a) Autoencoder basico"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#PEDIR LA FONT A UTILIZAR Y ARMAR EL TRAINING SET Y RESULT SET\n",
    "formattedFont = getFormattedFont(font)\n",
    "getCharacterMap(formattedFont[2])\n",
    "trainingSet = getFormattedFont(font,flatten=True)\n",
    "resultsSet = trainingSet\n",
    "print(trainingSet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #Seteo de seed\n",
    "# np.random.seed(randomSeed)\n",
    "# random.seed(randomSeed)\n",
    "# neuralNetworkManager = NeuralNetworkManager(architecture,activationFunction,learningRate,maxEpochs,maxToleranceExponent)\n",
    "# (epochs,executionTime,exception) = neuralNetworkManager.start(trainingSet,resultsSet)\n",
    "\n",
    "# #autoencoderManager = AutoencoderManager(architecture,activationFunction,learningRate,maxEpochs,errorHelper)\n",
    "# #(epochs,executionTime,exception) = autoencoderManager.start(trainingSet,resultsSet)\n",
    "\n",
    "# #Plot error graph\n",
    "# plotEpochsError(epochs)\n",
    "# #Print output\n",
    "# print(\"FINISH-------------------------------------------------------------------------------------------\")\n",
    "# output = Output(configHelper,epochs[-1].error,epochs[-1].epochNumber,executionTime)\n",
    "# output.printOutput()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ENTRENAMIENTO DE LA RED\n",
    "PATH = \"autoencoderW.pickle\"\n",
    "autoencoderManager = AutoencoderManager(architecture,encoderActivationFunction,latentSpaceActivationFunction,decoderActivationFunction,learningRate,maxEpochs)\n",
    "if exists(PATH):\n",
    "    print(\"INITIALIZING WEIGHTS FOR CONFIGURATION\")\n",
    "    file = open(PATH,'rb')\n",
    "    wFinal = pickle.load(file)\n",
    "    file.close()\n",
    "    autoencoderManager.initilizeWeights(trainingSet,wFinal)\n",
    "else:\n",
    "    print(\"CREATING WEIGHTS FOR CONFIGURATION\")\n",
    "    (wFinal,finalError) = autoencoderManager.start(trainingSet)\n",
    "    file = open(PATH,'wb')\n",
    "    pickle.dump(wFinal,file)\n",
    "    file.close()\n",
    "\n",
    "print(wFinal)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LATENT SPACE CONFIGURATION\n",
    "latentSpaceData = {\n",
    "    'X' : [],\n",
    "    'Y' : []\n",
    "}\n",
    "for character in trainingSet:\n",
    "    point = autoencoderManager.getLatentSpaceConfig(character)\n",
    "    latentSpaceData['X'].append(point[0])\n",
    "    latentSpaceData['Y'].append(point[1])\n",
    "data = pd.DataFrame(latentSpaceData)\n",
    "print(latentSpaceData)\n",
    "sns.scatterplot(x=\"X\",y=\"Y\",data=data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#GRAFICAR ERROR VS STEPS\n",
    "plotErrorAgainstSteps(autoencoderManager.errors,autoencoderManager.steps)\n",
    "print(autoencoderManager.steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PLOT INPUT VS OUTPUT OF FINAL LAYER\n",
    "figure, axes = plt.subplots( 2,len(formattedFont), sharex=True, figsize=(19,7))\n",
    "for font in range(0,len(formattedFont)):\n",
    "    getCharacterMap(formattedFont[font],ax=axes[0,font])\n",
    "    umbralFormattedCharacter = [x if x>=0.35 else 0 for x in autoencoderManager.propagate(trainingSet[font])]\n",
    "    getCharacterMap(getCharacterMatrix(np.array(umbralFormattedCharacter)),ax=axes[1,font])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### b) Denoising autoencoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ARMAMOS TRAINING SET CON RUIDO Y EL NUEVO RESULTS SET\n",
    "\n",
    "#Seteo de seed\n",
    "np.random.seed(randomSeed)\n",
    "random.seed(randomSeed)\n",
    "\n",
    "numberOfElements = 5\n",
    "#Agarramos las 10 primeras letras de la font\n",
    "flattenedSubFont = getFormattedFont(font,flatten=True)[:numberOfElements]\n",
    "# noiseProbability = 0.1\n",
    "numberOfSubFonts = 5\n",
    "#Armamos el trainingSet colocando las letras con distinto ruido segun la probabilidad especificada, y el resultsSet con las letras sin ruido\n",
    "newTrainingSet = []\n",
    "newResultsSet = []\n",
    "# for i in range(0,numberOfSubFonts):\n",
    "#     for j in range(0,len(flattenedSubFont)):\n",
    "#         newTrainingSet.append(addNoise(flattenedSubFont[j],noiseProbability))\n",
    "#         newResultsSet.append(flattenedSubFont[j])\n",
    "for j in range(0,len(flattenedSubFont)):\n",
    "    for i in range(0,numberOfSubFonts):\n",
    "        newTrainingSet.append(addNoise(flattenedSubFont[j],noiseProbability))\n",
    "        newResultsSet.append(flattenedSubFont[j])\n",
    "\n",
    "\n",
    "newTrainingSet = np.asarray(newTrainingSet)\n",
    "newResultsSet = np.asarray(newResultsSet)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# IMPRIMIMOS EL TRAINING SET Y EL RESULTS SET\n",
    "figure, axes = plt.subplots( 2,len(newTrainingSet), sharex=True, figsize=(19,7))\n",
    "for i in range(0,len(newTrainingSet)):\n",
    "    # print(newTrainingSet[i])\n",
    "    umbralTrainingFormattedCharacter = [x if x>=0.35 else 0 for x in newTrainingSet[i]]\n",
    "    getCharacterMap(getCharacterMatrix(np.array(umbralTrainingFormattedCharacter)),ax=axes[0,i])\n",
    "    umbralResultFormattedCharacter = [x if x>=0.35 else 0 for x in newResultsSet[i]]\n",
    "    getCharacterMap(getCharacterMatrix(np.array(umbralResultFormattedCharacter)),ax=axes[1,i])\n",
    "\n",
    "    # getCharacterMap(formattedFont[font],ax=axes[0,font])\n",
    "    # umbralFormattedCharacter = [x if x>=0.35 else 0 for x in autoencoderManager.propagate(trainingSet[font])]\n",
    "    # getCharacterMap(getCharacterMatrix(np.array(umbralFormattedCharacter)),ax=axes[1,font])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ENTRENAMIENTO DE LA RED\n",
    "\n",
    "denoisingAutoencoderManager = AutoencoderManager(architecture,encoderActivationFunction,latentSpaceActivationFunction,decoderActivationFunction,learningRate,maxEpochs)\n",
    "(wFinal,finalError) = denoisingAutoencoderManager.start(newTrainingSet,newResultsSet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TESTEO DE LA RED\n",
    "#Generamos un nuevo set de letras con ruido\n",
    "noiseSet = []\n",
    "resultsSet = flattenedSubFont\n",
    "for j in range(0,len(flattenedSubFont)):\n",
    "        noiseSet.append(addNoise(flattenedSubFont[j],noiseProbability))\n",
    "noiseSet = np.asarray(noiseSet)\n",
    "#Comparamos el input ruidoso con la salida de la red\n",
    "figure, axes = plt.subplots( 2,len(noiseSet), sharex=True, figsize=(19,7))\n",
    "for i in range(0,len(noiseSet)):\n",
    "    umbralTrainingFormattedCharacter = [x if x>=0.35 else 0 for x in noiseSet[i]]\n",
    "    getCharacterMap(getCharacterMatrix(np.array(umbralTrainingFormattedCharacter)),ax=axes[0,i])\n",
    "#     umbralResultFormattedCharacter = [x if x>=0.35 else 0 for x in newResultsSet[i]]\n",
    "#     getCharacterMap(getCharacterMatrix(np.array(umbralResultFormattedCharacter)),ax=axes[1,i])\n",
    "#     getCharacterMap(formattedFont[font],ax=axes[0,font])\n",
    "    umbralResultFormattedCharacter = [x if x>=0.35 else 0 for x in denoisingAutoencoderManager.propagate(noiseSet[i])]\n",
    "    getCharacterMap(getCharacterMatrix(np.array(umbralResultFormattedCharacter)),ax=axes[1,i])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.2 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "26de051ba29f2982a8de78e945f0abaf191376122a1563185a90213a26c5da77"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
